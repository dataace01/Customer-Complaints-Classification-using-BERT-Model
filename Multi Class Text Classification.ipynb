{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4ed5fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec697d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "seq_len = 20\n",
    "dropout = 0.5\n",
    "num_epochs = 10\n",
    "label_col = \"Product\"\n",
    "tokens_path = r\"C:\\Users\\conta\\OneDrive\\Desktop\\Projects\\NLP Project  using BERT Model\\Modular_code\\Modular_code\\Output\\tokens.pkl\"\n",
    "labels_path = r\"C:\\Users\\conta\\OneDrive\\Desktop\\Projects\\NLP Project  using BERT Model\\Modular_code\\Modular_code\\Output\\labels.pkl\"\n",
    "data_path = r\"C:\\Users\\conta\\OneDrive\\Desktop\\Projects\\NLP Project  using BERT Model\\Modular_code\\Modular_code\\Input\\complaints.csv\"\n",
    "model_path = r\"C:\\Users\\conta\\OneDrive\\Desktop\\Projects\\NLP Project  using BERT Model\\Modular_code\\Modular_code\\Output\\bert_pre_trained.pth\"\n",
    "text_col_name = \"Consumer complaint narrative\"\n",
    "label_encoder_path = r\"C:\\Users\\conta\\OneDrive\\Desktop\\Projects\\NLP Project  using BERT Model\\Modular_code\\Modular_code\\Output\\label_encoder.pkl\"\n",
    "product_map = {'Vehicle loan or lease': 'vehicle_loan',\n",
    "               'Credit reporting, credit repair services, or other personal consumer reports': 'credit_report',\n",
    "               'Credit card or prepaid card': 'card',\n",
    "               'Money transfer, virtual currency, or money service': 'money_transfer',\n",
    "               'virtual currency': 'money_transfer',\n",
    "               'Mortgage': 'mortgage',\n",
    "               'Payday loan, title loan, or personal loan': 'loan',\n",
    "               'Debt collection': 'debt_collection',\n",
    "               'Checking or savings account': 'savings_account',\n",
    "               'Credit card': 'card',\n",
    "               'Bank account or service': 'savings_account',\n",
    "               'Credit reporting': 'credit_report',\n",
    "               'Prepaid card': 'card',\n",
    "               'Payday loan': 'loan',\n",
    "               'Other financial service': 'others',\n",
    "               'Virtual currency': 'money_transfer',\n",
    "               'Student loan': 'loan',\n",
    "               'Consumer Loan': 'loan',\n",
    "               'Money transfers': 'money_transfer'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4da2b9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(name, obj):\n",
    "    \"\"\"\n",
    "    Function to save an object as pickle file\n",
    "    \"\"\"\n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "\n",
    "def load_file(name):\n",
    "    \"\"\"\n",
    "    Function to load a pickle object\n",
    "    \"\"\"\n",
    "    return pickle.load(open(name, \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64246157",
   "metadata": {},
   "source": [
    "## Process text data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccad4958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date received</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sub-product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Sub-issue</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <th>Company public response</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>ZIP code</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Consumer consent provided?</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Date sent to company</th>\n",
       "      <th>Company response to consumer</th>\n",
       "      <th>Timely response?</th>\n",
       "      <th>Consumer disputed?</th>\n",
       "      <th>Complaint ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-13</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Incorrect information on your report</td>\n",
       "      <td>Information belongs to someone else</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CAPITAL ONE FINANCIAL CORPORATION</td>\n",
       "      <td>PA</td>\n",
       "      <td>186XX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-06-13</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3274605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>Vehicle loan or lease</td>\n",
       "      <td>Loan</td>\n",
       "      <td>Struggling to pay your loan</td>\n",
       "      <td>Denied request to lower payments</td>\n",
       "      <td>I contacted Ally on Friday XX/XX/XXXX after fa...</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>ALLY FINANCIAL INC.</td>\n",
       "      <td>NJ</td>\n",
       "      <td>088XX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3425257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Incorrect information on your report</td>\n",
       "      <td>Account status incorrect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>TRANSUNION INTERMEDIATE HOLDINGS, INC.</td>\n",
       "      <td>PA</td>\n",
       "      <td>19067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3198225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Problem with a credit reporting company's inve...</td>\n",
       "      <td>Was not notified of investigation status or re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRANSUNION INTERMEDIATE HOLDINGS, INC.</td>\n",
       "      <td>GA</td>\n",
       "      <td>31707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web</td>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>In progress</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4863965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Medical debt</td>\n",
       "      <td>Took or threatened to take negative or legal a...</td>\n",
       "      <td>Threatened or suggested your credit would be d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medical Data Systems, Inc.</td>\n",
       "      <td>VA</td>\n",
       "      <td>22033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web</td>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>In progress</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4866449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date received                                            Product  \\\n",
       "0    2019-06-13  Credit reporting, credit repair services, or o...   \n",
       "1    2019-11-01                              Vehicle loan or lease   \n",
       "2    2019-04-01  Credit reporting, credit repair services, or o...   \n",
       "3    2021-11-01  Credit reporting, credit repair services, or o...   \n",
       "4    2021-11-02                                    Debt collection   \n",
       "\n",
       "        Sub-product                                              Issue  \\\n",
       "0  Credit reporting               Incorrect information on your report   \n",
       "1              Loan                        Struggling to pay your loan   \n",
       "2  Credit reporting               Incorrect information on your report   \n",
       "3  Credit reporting  Problem with a credit reporting company's inve...   \n",
       "4      Medical debt  Took or threatened to take negative or legal a...   \n",
       "\n",
       "                                           Sub-issue  \\\n",
       "0                Information belongs to someone else   \n",
       "1                   Denied request to lower payments   \n",
       "2                           Account status incorrect   \n",
       "3  Was not notified of investigation status or re...   \n",
       "4  Threatened or suggested your credit would be d...   \n",
       "\n",
       "                        Consumer complaint narrative  \\\n",
       "0                                                NaN   \n",
       "1  I contacted Ally on Friday XX/XX/XXXX after fa...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                             Company public response  \\\n",
       "0                                                NaN   \n",
       "1  Company has responded to the consumer and the ...   \n",
       "2  Company has responded to the consumer and the ...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                  Company State ZIP code Tags  \\\n",
       "0       CAPITAL ONE FINANCIAL CORPORATION    PA    186XX  NaN   \n",
       "1                     ALLY FINANCIAL INC.    NJ    088XX  NaN   \n",
       "2  TRANSUNION INTERMEDIATE HOLDINGS, INC.    PA    19067  NaN   \n",
       "3  TRANSUNION INTERMEDIATE HOLDINGS, INC.    GA    31707  NaN   \n",
       "4              Medical Data Systems, Inc.    VA    22033  NaN   \n",
       "\n",
       "  Consumer consent provided? Submitted via Date sent to company  \\\n",
       "0       Consent not provided           Web           2019-06-13   \n",
       "1           Consent provided           Web           2019-11-01   \n",
       "2       Consent not provided           Web           2019-04-01   \n",
       "3                        NaN           Web           2021-11-01   \n",
       "4                        NaN           Web           2021-11-02   \n",
       "\n",
       "  Company response to consumer Timely response? Consumer disputed?  \\\n",
       "0      Closed with explanation              Yes                NaN   \n",
       "1      Closed with explanation              Yes                NaN   \n",
       "2      Closed with explanation              Yes                NaN   \n",
       "3                  In progress              Yes                NaN   \n",
       "4                  In progress              Yes                NaN   \n",
       "\n",
       "   Complaint ID  \n",
       "0       3274605  \n",
       "1       3425257  \n",
       "2       3198225  \n",
       "3       4863965  \n",
       "4       4866449  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45e6a0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset=[text_col_name], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e14a0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace({label_col: product_map}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7207cee2",
   "metadata": {},
   "source": [
    "### Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49752a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(data[label_col])\n",
    "labels = label_encoder.transform(data[label_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7b912ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file(labels_path, labels)\n",
    "save_file(label_encoder_path, label_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53e405c",
   "metadata": {},
   "source": [
    "### Process the text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34ffaab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = list(data[text_col_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b26b2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will run only 8000 for faster results\n",
    "input_text = input_text[:8000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14034928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a867d36",
   "metadata": {},
   "source": [
    "### Convert text to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ad2a95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 8000/8000 [00:00<00:00, 604268.62it/s]\n"
     ]
    }
   ],
   "source": [
    "input_text = [i.lower() for i in tqdm(input_text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cd359f",
   "metadata": {},
   "source": [
    "### Remove punctuations except apostrophe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e1cde62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 8000/8000 [00:00<00:00, 28330.68it/s]\n"
     ]
    }
   ],
   "source": [
    "input_text = [re.sub(r\"[^\\w\\d'\\s]+\", \" \", i)\n",
    "             for i in tqdm(input_text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f4a1f5",
   "metadata": {},
   "source": [
    "### Remove digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d610a9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 8000/8000 [00:00<00:00, 45749.58it/s]\n"
     ]
    }
   ],
   "source": [
    "input_text = [re.sub(\"\\d+\", \"\", i) for i in tqdm(input_text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6157ab6e",
   "metadata": {},
   "source": [
    "### Remove more than one consecutive instance of 'x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e765d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 8000/8000 [00:00<00:00, 64059.75it/s]\n"
     ]
    }
   ],
   "source": [
    "input_text = [re.sub(r'[x]{2,}', \"\", i) for i in tqdm(input_text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74b80fc",
   "metadata": {},
   "source": [
    "### Remove multiple spaces with single space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68c399a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 8000/8000 [00:00<00:00, 21290.61it/s]\n"
     ]
    }
   ],
   "source": [
    "input_text = [re.sub(' +', ' ', i) for i in tqdm(input_text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fa09e2",
   "metadata": {},
   "source": [
    "### Tokenize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5232d10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c606d801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i contacted ally on friday after falling behind on payments due to being out of work for a short period of time due to an illness i chated with a representative after logging into my account regarding my opitions to ensure i protect my credit and bring my account current \\n\\nshe advised me that before an extenstion could be done i had to make a payment in the amount of i reviewed my finances as i am playing catch up on all my bills and made this payment on monday this rep advised me once this payment posts to my account to contact ally back for an extention or to have a payment deffered to the end of my loan \\n\\nwith this in mind i contacted ally again today and chatted with i explained all of the above and the information i was provided when i chatted with the rep last week she asked several questions and advised me that a one or two month extension deffered payment could be done however partial payment is needed what she advised me or there abouts would be due within days from me accepting the agreement and then the remaining bal of or there abouts would be due in in my payments of per month would resume \\n\\nif this was the case i should have just been offered this when i just made my payment so that i could catch up on my bills \\n\\nthis company was working with in new jersey which has since closed most likely due to illegal practices they changed my loan company to this company after i had signed paperwork for another kill you with interest rates and has never once considered refiancing my vechile for a lower interest rate due to the age of the vechile other companies will not take it and they do not work with you '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51ba20a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tokens = tokenizer(input_text[0], padding=\"max_length\",\n",
    "                         max_length=seq_len, truncation=True,\n",
    "                         return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03334517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,   178, 12017, 11989,  1113,   175, 22977,  1183,  1170,  4058,\n",
       "          1481,  1113, 10772,  1496,  1106,  1217,  1149,  1104,  1250,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d7a9ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,   178, 12017, 11989,  1113,   175, 22977,  1183,  1170,  4058,\n",
       "          1481,  1113, 10772,  1496,  1106,  1217,  1149,  1104,  1250,   102]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tokens[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af51439b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tokens[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "587aa9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 8000/8000 [00:27<00:00, 294.04it/s]\n"
     ]
    }
   ],
   "source": [
    "tokens = [tokenizer(i, padding=\"max_length\", max_length=seq_len, \n",
    "                    truncation=True, return_tensors=\"pt\") \n",
    "         for i in tqdm(input_text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1271b5c2",
   "metadata": {},
   "source": [
    "### Save the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b51be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file(tokens_path, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323823d5",
   "metadata": {},
   "source": [
    "## Create Bert model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4543e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b32327e",
   "metadata": {},
   "source": [
    "## Create PyTorch Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2969357",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d140aa21",
   "metadata": {},
   "source": [
    "### Function to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6deedcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, valid_loader, model, criterion, optimizer, \n",
    "          device, num_epochs, model_path):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc7f7da",
   "metadata": {},
   "source": [
    "### Function to test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19be319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model, criterion, device):\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e896845",
   "metadata": {},
   "source": [
    "## Train Bert model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d98212",
   "metadata": {},
   "source": [
    "### Load the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "321f7a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = load_file(tokens_path)\n",
    "labels = load_file(labels_path)\n",
    "label_encoder = load_file(label_encoder_path)\n",
    "num_classes = len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c900a757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for speed up only 8000\n",
    "labels = labels[:8000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1619263d",
   "metadata": {},
   "source": [
    "### Split data into train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6178ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tokens, labels,\n",
    "                                                   test_size=0.2)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, \n",
    "                                                      y_train,\n",
    "                                                     test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae6c092",
   "metadata": {},
   "source": [
    "### Create PyTorch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2202470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(X_train, y_train)\n",
    "valid_dataset = TextDataset(X_valid, y_valid)\n",
    "test_dataset = TextDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe3d735",
   "metadata": {},
   "source": [
    "### Create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d03cf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=16,\n",
    "                                           shuffle=True,\n",
    "                                           drop_last=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                           batch_size=16)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                         batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c882cf2",
   "metadata": {},
   "source": [
    "### Create model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e1c92f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available()\n",
    "                     else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6053ecaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertClassifier(dropout, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ecf048",
   "metadata": {},
   "source": [
    "### Define loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "794e3c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1665a786",
   "metadata": {},
   "source": [
    "### Move the model to GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19c0dfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d331f9f8",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ffb8343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 300/300 [08:26<00:00,  1.69s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:44<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.7030835258960724, Validation Loss: 1.6930737668275833\n",
      "Best Validation Loss: 1.6930737668275833\n",
      "Epoch 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 300/300 [08:38<00:00,  1.73s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:49<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6930189522107442, Validation Loss: 1.6753383910655975\n",
      "Best Validation Loss: 1.6753383910655975\n",
      "Epoch 3 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 300/300 [13:23<00:00,  2.68s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:33<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.7490395891666413, Validation Loss: 1.682252868413925\n",
      "Best Validation Loss: 1.6753383910655975\n",
      "Epoch 4 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 300/300 [09:35<00:00,  1.92s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:51<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.7182658741871515, Validation Loss: 1.689323068857193\n",
      "Best Validation Loss: 1.6753383910655975\n",
      "Epoch 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 300/300 [3:46:17<00:00, 45.26s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:45<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.719649334748586, Validation Loss: 1.6949700462818145\n",
      "Best Validation Loss: 1.6753383910655975\n",
      "Epoch 6 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 300/300 [17:10:43<00:00, 206.15s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:38<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6981363727649053, Validation Loss: 1.6659053421020509\n",
      "Best Validation Loss: 1.6659053421020509\n",
      "Epoch 7 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 300/300 [09:52<00:00,  1.98s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:47<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6861442536115647, Validation Loss: 1.7162499260902404\n",
      "Best Validation Loss: 1.6659053421020509\n",
      "Epoch 8 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 300/300 [08:09<00:00,  1.63s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:37<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6848732642332713, Validation Loss: 1.6718441593647002\n",
      "Best Validation Loss: 1.6659053421020509\n",
      "Epoch 9 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 300/300 [09:03<00:00,  1.81s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:40<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6878118932247161, Validation Loss: 1.6759009492397308\n",
      "Best Validation Loss: 1.6659053421020509\n",
      "Epoch 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 300/300 [08:43<00:00,  1.74s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:39<00:00,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.685974834561348, Validation Loss: 1.6787320041656495\n",
      "Best Validation Loss: 1.6659053421020509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(train_loader, valid_loader, model, criterion, optimizer,\n",
    "     device, num_epochs, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426c4238",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c9a2cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:40<00:00,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.6601996886730195, Test Accuracy: 0.453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test(test_loader, model, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbb7a07",
   "metadata": {},
   "source": [
    "## Predict on new text\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5e7b40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = '''I am a victim of Identity Theft & currently have an Experian account that \n",
    "I can view my Experian Credit Report and getting notified when there is activity on \n",
    "my Experian Credit Report. For the past 3 days I've spent a total of approximately 9 \n",
    "hours on the phone with Experian. Every time I call I get transferred repeatedly and \n",
    "then my last transfer and automated message states to press 1 and leave a message and \n",
    "someone would call me. Every time I press 1 I get an automatic message stating than you \n",
    "before I even leave a message and get disconnected. I call Experian again, explain what \n",
    "is happening and the process begins again with the same end result. I was trying to have \n",
    "this issue attended and resolved informally but I give up after 9 hours. There are hard \n",
    "hit inquiries on my Experian Credit Report that are fraud, I didn't authorize, or recall \n",
    "and I respectfully request that Experian remove the hard hit inquiries immediately just \n",
    "like they've done in the past when I was able to speak to a live Experian representative \n",
    "in the United States. The following are the hard hit inquiries : BK OF XXXX XX/XX/XXXX \n",
    "XXXX XXXX XXXX  XX/XX/XXXX XXXX  XXXX XXXX  XX/XX/XXXX XXXX  XX/XX/XXXX XXXX  XXXX \n",
    "XX/XX/XXXX'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1a65bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = input_text.lower()\n",
    "input_text = re.sub(r\"[^\\w\\d'\\s]+\", \" \", input_text)\n",
    "input_text = re.sub(\"\\d+\", \"\", input_text)\n",
    "input_text = re.sub(r'[x]{2,}', \"\", input_text)\n",
    "input_text = re.sub(' +', ' ', input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e724e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "868f2a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(input_text, padding=\"max_length\",\n",
    "                 max_length=seq_len, truncation=True,\n",
    "                 return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "62b0bd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokens[\"input_ids\"]\n",
    "attention_mask = tokens[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "565f8ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available()\n",
    "                     else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1d1b7751",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = input_ids.to(device)\n",
    "attention_mask = attention_mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "82fb78ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.squeeze(input_ids, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d87b4155",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = load_file(label_encoder_path)\n",
    "num_classes = len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b9721e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: credit_report\n"
     ]
    }
   ],
   "source": [
    "# Create model object\n",
    "model = BertClassifier(dropout, num_classes)\n",
    "\n",
    "# Load trained weights\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# Move the model to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    \n",
    "# Forward pass\n",
    "out = torch.squeeze(model(input_ids, attention_mask))\n",
    "\n",
    "# Find predicted class\n",
    "prediction = label_encoder.classes_[torch.argmax(out)]\n",
    "print(f\"Predicted Class: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669c90fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
